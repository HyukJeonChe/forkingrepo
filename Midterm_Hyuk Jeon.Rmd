---
title: "Midterm"
author: "Hyuk Jeon"
date: "2022-07-15"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidycensus)
library(textdata)
library(tidytext)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(rvest)
```
# This is my mid-term project submitted in the Canvas.

1)  U <- c(“Maine” , “Texas”, “Delaware”, “Oregon”, “Utah”, “Vermont”, “Ohio”)
a)  Is U an atomic vector or a list ?

```{r}
U <- c("Maine" , "Texas", "Delaware", "Oregon", "Utah", "Vermont", "Ohio")

typeof(U)
# U is an atomic vector of characters
```

b)  Use and show R code that will extract the elements  “Maine” and “Vermont”.

```{r}
U[c(1,6)]
```
c)  Use and show R code that will extract all elements except “Texas”.

```{r}
U[-2]
```

d)  Use and show R code that will produce length of U.
```{r}
length(U)
```


2)  V = list(“Chicago”, k = list( 2, 6, 18, 24), FALSE, 13, 1.3,  y = 1:10)
a)  Is V an atomic vector or a list ?
```{r}
V = list("Chicago", k = list( 2, 6, 18, 24), FALSE, 13, 1.3,  y = 1:10)

typeof(V)
# V is a list
```

b)  Use and show R code that will extract the 5th element of V.
```{r}
V[[5]]
```

c)  If the vector V is a list, use and show R code to identify the type of each object in V.
```{r}
str(V)
```

3) Copy paste and run the tribble given below.
```{r}
tribble( ~John,    ~Raymond,    ~Martha,    ~Alice,   ~Juan,
              86,            77,                  81,              88,           90,
              79,            78,                  85,              81,           78,
              76,            75,                  88,              94,           81,
              84,            90,                  71,              84,           89,
              100,           80,                  93,              85,           84,
              90,            73,                  70,              88,           93,
) -> TestScores
TestScores

```
a) Use and show R code (a map function) to find the median for each column.
```{r}
map_dbl(TestScores, median)
```

b) Use and show R code (a map function) to find the cube root of each column element.
```{r}
TestScores %>% 
  map(~. ^(1/3))
```
c)  Use and show R code (a map function) to convert each column value to 0.
```{r}
TestScores %>% 
  map(~. *0)
```
4)  Use and show R code, as demonstrated in class to produce the following matrix.
![](./table_midterm.png)
```{r}
matrix1 <- matrix(ncol = 4, nrow = 3)
for(i in 1:nrow(matrix1)){
  for(j in 1:ncol(matrix1)){
    matrix1[i,j] = -(i+j)^2
  }
}
matrix1 
```

5)
a) Show and use a census API key that gives you access to the ACS data. Do not use my API key, use and show your own key.

```{r}
census_api_key("2e4af405c727bfe259d82e61ff791dd9192d95b4")
install = TRUE
```

b) Using ACS census data from 2015, show and use R code to do the following to produce a tibble that shows the median income estimates and the margin of errors for white males ages    35 - 44 in the counties of California.  The required variable code starts with the characters BO1OO1. Use the table to find the other characters.
The first five rows of your data table are provided below:

```{r}
acs_2015 <- load_variables(2015, "acs5", cache = TRUE)

cal_2015 <- get_acs(geography = "county", 
              variables = c(medincome = "B01001A_011"), 
              state = "CA", 
              year = 2015)

head(cal_2015, 5)
```

c) Use  dplyr functions to change your table of part a so that it reflects estimates that are greater than $30,000 dollars and list the estimates in descending order.
```{r}
cal_2015_gr <- cal_2015 %>% 
  mutate(NAME = gsub(" County, California", "", NAME)) %>% 
  filter(estimate > 30000) %>% 
  arrange(desc(estimate))

cal_2015_gr
```

d)  Use and show ggplot R coding to produce a scatter plot that features x = natural log of moe plotted against   y = natural log of estimate.  Does your plot suggest a linear relationship between the variables ?  If so, what general trend can be inferred?  (Use the full data table that you generated for part b)

```{r}
cal_2015 %>% 
  mutate(NAME = gsub(" County, California", "", NAME)) %>% 
  ggplot(aes(x = log(moe), y = log(estimate))) +
  geom_point() +
  geom_smooth(mothod = 'lm')

# The plot shows a positive linear relationship between log of moe and log of estimate. It means that if margin of error increases, median income estimate also goes up.
```

e) Use and show R code that will produce the following graph for the data generated in part c
```{r}

cal_2015_gr
ggplot(data = cal_2015_gr, aes(x = estimate, y = reorder(NAME, estimate)))+
  geom_errorbarh(aes(xmin = estimate-moe, xmax = estimate +moe))+
  geom_point(color = "blue", size = 2)+
  labs(title = "Median Income for White Males by County", 
       subtitle = "2014-2018 American Community Survey",
       y = "",
       x = "ACS estimate (bars represent margin of error)")
```

6) Provided below is the famous poem  “ Stopping by the Wood On a Snowy Evening”  by Robert Frost.
Use the text mining sequence of steps and the R code modeled in class to a) create a tibble, 
```{r}
text <- c("Whose woods these are I think I know.",
"His house is in the village though;",
"He will not see me stopping here",
"To watch his woods fill up with snow.",
"My little horse must think it queer",
"To stop without a farmhouse near",
"Between the woods and frozen lake",
"The darkest evening of the year.",
"He gives his harness bells a shake",
"To ask if there is some mistake.",
"The only other sound’s the sweep",
"Of easy wind and downy flake.",
"The woods are lovely, dark and deep,",
"But I have promises to keep,",
"And miles to go before I sleep,",
"And miles to go before I sleep."
)

frost <- tibble(line = 161:176, text = text)

frost

```
b) find line locations of words,
```{r}
frost_word <- frost %>% 
  unnest_tokens(word, text)

frost_word
```

c) produce a word frequency table
```{r}
frost_word_c <- frost_word %>% 
  count(word, sort = TRUE) %>% 
  filter(n >= 1)

```
d) and create a bar graph data visualization plot that will also display word frequency trends.
```{r}
frost_word_c %>% 
  ggplot(aes(x = n, y = reorder(word, n))) +
  geom_col(fill = "blue", color = "red") +
  labs(y = "")
```

Hint( do not forget to process a single spaced body of text ; be careful about commas and double quotation marks. Use the examples demonstrated in class.)

7) Now using the same body of text found in Problem 6, use and show R code to create a word cloud.  You can use the coding and methods that were illustrated in class or you can use alternate coding of your choice to create the word cloud.
```{r}
docs <- Corpus(VectorSource(frost))
docs
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)


set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

8)  Go to the link  https://www.imdb.com/list/ls096735829 and use Selector Gadget , as demonstrated in class to collect data specific to the movie names, the directors of the movies, the movie ratings, and the running times of the movies.  Your code should produce the final resulting table given below.   Hint:  (you may have to first create a data frame, and then convert the data frame to the tibble shown below.

```{r}

Link <- "https://www.imdb.com/list/ls096735829"
page = read_html(Link)

Movies2020 = page%>% html_nodes(".lister-item-header a")%>%
html_text()

Directors2020 = page%>% html_nodes(".text-muted a:nth-child(1)")%>%
html_text()

Ratings2020 = page%>% html_nodes(".ipl-rating-star.small .ipl-rating-star__rating")%>%
html_text()

Runtime2020 = page%>% html_nodes(".runtime")%>%
html_text()

movies2020 <- data.frame(Movies2020, Directors2020, Ratings2020, Runtime2020)

print(movies2020)
```
The following problem is for Graduate students only  (Use the diamonds data table)
9)  
a) Use and show R code that shows both column variables x and y, of the diamonds data    table contain the value 4.93. How many times does the number 4.93 appear in each column ?

```{r}
data("diamonds")
diamonds %>% 
  select(x) %>% 
  filter(x == 4.93) %>% 
  count(x) #42

diamonds %>% 
  select(y) %>% 
  filter(y == 4.93) %>% 
  count(y) #50

diamonds %>% 
  select(x, y) %>% 
  filter(x == 4.93 & y == 4.93) #0

# The column of X has 42 values of 4.93 and the column of y has 50 values of 4.93. Since there is no case that both x and y have 4.93 at the same time, the answer is 92.

```

b) Use and show R code that shows neither column variable x or y, contain the value 3.62.

```{r}
diamonds %>% 
  filter(x != 3.62 & y != 3.62) 

```

c) Now show and use R code to find all values that the column variables x and y have in common.
```{r}
diamonds %>% 
  filter(x == y)

```
